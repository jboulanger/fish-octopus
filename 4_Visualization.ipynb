{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and statistical analysis\n",
    "\n",
    "- Inclusive count: cells positive in any of the channel combination, then it is positive for this combination of channels.\n",
    "- Exclusive count: cells positive in all of the channel combination, then it is positive for this combination of channels and is associated to this category.\n",
    "\n",
    "Save the results as a 'destination folder/*-stats.csv' file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the result folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "srcdir, dstdir = \"\", \"\"\n",
    "if Path(\"config.yml\").exists():\n",
    "    with open(\"config.yml\", \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        if \"source\" in config.keys():\n",
    "            srcdir = Path(config[\"source\"])\n",
    "        if \"destination\" in config.keys():\n",
    "            dstdir = Path(config[\"destination\"])\n",
    "\n",
    "fc = FileChooser(dstdir, select_desc=\"Destination\")\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dstdir = Path(fc.selected) if fc.selected is not None else Path(dstdir)\n",
    "filelistname = dstdir / \"filelist.csv\"\n",
    "filelist = pd.read_csv(filelistname)\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "from functools import partial\n",
    "from functools import reduce\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import napari\n",
    "import dask\n",
    "\n",
    "\n",
    "def get_files(dstdir, row, key=None):\n",
    "    if key == \"ims\":\n",
    "        return Path(row[\"folder\"]) / row[\"name\"]\n",
    "    elif key == \"regions\":\n",
    "        return Path(dstdir / str(row[\"name\"]).replace(\".ims\", \"-regions.json\"))\n",
    "    elif key == \"labels\":\n",
    "        return Path(dstdir / str(row[\"name\"]).replace(\".ims\", \"-labels.tif\"))\n",
    "    elif key == \"measurements\":\n",
    "        return Path(dstdir / str(row[\"name\"]).replace(\".ims\", \"-measurements.csv\"))\n",
    "    elif key == \"stats\":\n",
    "        return Path(dstdir / str(row[\"name\"]).replace(\".ims\", \"-stats.csv\"))\n",
    "    else:\n",
    "        return {\n",
    "            \"ims\": get_files(dstdir, row, \"ims\"),\n",
    "            \"regions\": get_files(dstdir, row, \"regions\"),\n",
    "            \"labels\": get_files(dstdir, row, \"labels\"),\n",
    "            \"measurements\": get_files(dstdir, row, \"measurements\"),\n",
    "        }\n",
    "\n",
    "\n",
    "def get_measurement_channels(df):\n",
    "    \"\"\"List the channels name from the measurement data\"\"\"\n",
    "    return df.columns[6:]\n",
    "\n",
    "\n",
    "def create_heatmaps(labels, df):\n",
    "    channel_columns = [f\"c{k}\" for k in range(10) if f\"c{k}\" in df.columns]\n",
    "\n",
    "    heatmaps = np.zeros([len(channel_columns), *labels.shape])\n",
    "    for row in df.iloc:\n",
    "        for k, c in enumerate(channel_columns):\n",
    "            heatmaps[k][labels == row[\"label\"]] = row[c]\n",
    "    return heatmaps\n",
    "\n",
    "\n",
    "def madstd(x):\n",
    "    \"\"\"Median std\"\"\"\n",
    "    return 1.48 * np.median(np.abs(x - np.median(x)))\n",
    "\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"Compute the powerset of iterable\"\"\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))\n",
    "\n",
    "\n",
    "def encode(row, channels, thresholds, encoder):\n",
    "    \"\"\"compute a code from the channels columns and the tresholds\"\"\"\n",
    "    t = tuple([c for c in channels if row[c] > thresholds[c]])\n",
    "    return encoder[t]\n",
    "\n",
    "\n",
    "def encode_channels_exclusive(df, columns, thresholds):\n",
    "    \"\"\"Encode the channel in the data frame based on intensity\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    columns : List[str]\n",
    "        list of columns names\n",
    "    thresholds: List[float]\n",
    "        list of threshold values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    code_df and encoder, decoder dicts\n",
    "    \"\"\"\n",
    "    pset = [x for x in powerset(columns)]\n",
    "    encoder = {x: k for k, x in enumerate(pset)}\n",
    "    decoder = {k: x for k, x in enumerate(pset)}\n",
    "    decoder[0] = (\"none\",)\n",
    "    decode_str = {\n",
    "        a: b\n",
    "        for a, b in enumerate([\"+\".join([str(e) for e in k]) for k in encoder.keys()])\n",
    "    }\n",
    "    cid = df.apply(\n",
    "        partial(encode, channels=columns, encoder=encoder, thresholds=thresholds),\n",
    "        axis=1,\n",
    "    )\n",
    "    code_df = pd.DataFrame({\"label\": df[\"label\"], \"id\": cid})\n",
    "    return code_df, decoder\n",
    "\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "\n",
    "def encode_channels_inclusive(df, columns, thresholds):\n",
    "    \"\"\"Encode the channel in the data frame based on intensity\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    channels : List[str]\n",
    "        list of channel names\n",
    "    thresholds: List[float]\n",
    "        list of threshold values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    code_df and encoder, decoder dicts\n",
    "    \"\"\"\n",
    "    pset = [x for x in powerset(columns)]\n",
    "    decoder = {k + 1: \"+\".join([str(e) for e in x]) for k, x in enumerate(pset[1:])}\n",
    "    code_df = pd.DataFrame(\n",
    "        {\n",
    "            \"+\".join([str(e) for e in k]): prod([df[e] > thresholds[e] for e in k])\n",
    "            for k in pset[1:]\n",
    "        }\n",
    "    )\n",
    "    code_df[\"label\"] = df[\"label\"]\n",
    "    return code_df, decoder\n",
    "\n",
    "def create_class_image(labels, codes, decoder, chunk_size=20):\n",
    "    \"\"\"Create a map of the binary codes as a label map\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    labels: np.array\n",
    "\n",
    "    codes: pd.DataFrame\n",
    "        data frame with a column label and a label code\n",
    "\n",
    "    decoder: dict\n",
    "        dictionary: {id: tuple(combination columns names)}\n",
    "\n",
    "    Note add 1 to the code so that it is not set to background\n",
    "    \"\"\"\n",
    "    def helper(stack, labels, codes, decoder):\n",
    "        for row in codes.iloc:\n",
    "            stack[labels == row[\"label\"]] = row[\"id\"] + 1\n",
    "    \n",
    "    stack = np.zeros(labels.shape, dtype=np.uint8)\n",
    "\n",
    "    tsk = [\n",
    "        dask.delayed(helper)(\n",
    "            stack, labels, codes.iloc[n : n + chunk_size], decoder\n",
    "        )\n",
    "        for n in range(0, codes.shape[0], chunk_size)\n",
    "    ]\n",
    "    \n",
    "    dask.compute(tsk)\n",
    "\n",
    "    features = pd.DataFrame(\n",
    "        {\"code\": [\"background\", *[\" + \".join(decoder[k]) for k in decoder]]}\n",
    "    )\n",
    "    return stack, features\n",
    "\n",
    "def create_class_masks(labels, codes, decoder, chunk_size=20):\n",
    "    \"\"\"Create a set of maps for each combination of labels\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    labels: np.array\n",
    "\n",
    "    codes: pd.DataFrame\n",
    "        data frame with a column label and a column per combination\n",
    "\n",
    "    decoder: dict\n",
    "        dictionary: {id: tuple(combination columns names)}\n",
    "\n",
    "    \"\"\"\n",
    "    nc = len(decoder)\n",
    "    stack = np.zeros([nc, *labels.shape], dtype=np.uint8)\n",
    "\n",
    "    def helper(stack, labels, codes, decoder):\n",
    "        for row in codes.iloc:\n",
    "            for c in decoder:\n",
    "                if row[decoder[c]] == 1:\n",
    "                    stack[c - 1][labels == row[\"label\"]] = 255\n",
    "\n",
    "    tsk = [\n",
    "        dask.delayed(helper)(\n",
    "            stack, labels, codes.iloc[n : n + chunk_size], decoder\n",
    "        )\n",
    "        for n in range(0, codes.shape[0], chunk_size)\n",
    "    ]\n",
    "\n",
    "    dask.compute(tsk)\n",
    "    names = [decoder[k] for k in decoder]\n",
    "    return stack, names\n",
    "\n",
    "\n",
    "def aggregate_combinations(input, decoder):\n",
    "    \"\"\"Aggregate the inputs based on combinations in the decoder\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input: pd.DataFrame or np.array\n",
    "        input on which to compute the aggregation\n",
    "    decoder: dict\n",
    "        mapping between keys of the input and the corresponding set of channels\n",
    "    \"\"\"\n",
    "    output = input.copy()\n",
    "    for k1 in decoder:\n",
    "        for k2 in decoder:\n",
    "            if len(decoder[k2]) > len(decoder[k1]):\n",
    "                for y1 in decoder[k1]:\n",
    "                    if y1 in decoder[k2]:\n",
    "                        output[k1] = output[k1] + input[k2]\n",
    "    return output\n",
    "\n",
    "def map_intensity(labels, df, channels, chunk_size=20):\n",
    "    \"\"\"Set each label with the intensity store in the dataframe df\n",
    "\n",
    "    The purpose of this is to help ind the adequate threshold\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: ndarray (D,H,W)\n",
    "        labels of the segmented nuclei in 3D\n",
    "    df: pd.dataframe\n",
    "        data frame with intensity measurement and matching labels indices\n",
    "    channels: List\n",
    "        list of the channels\n",
    "    chunk_size: int\n",
    "        size of the chunck\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    map : ndarray (C,D,H,W)\n",
    "        intensity map for each label\n",
    "    \"\"\"\n",
    "    \n",
    "    def helper(dst, labels, df, channels):\n",
    "        for row in df.iloc:\n",
    "            idx = labels == row[\"label\"]\n",
    "            for k, ch in enumerate(channels):\n",
    "                dst[k][idx] = row[ch]\n",
    "\n",
    "    dst = np.zeros((len(channels), *labels.shape))\n",
    "    tsk = [\n",
    "        dask.delayed(helper)(\n",
    "            dst, labels, df.iloc[n : n + chunk_size], channels\n",
    "        )\n",
    "        for n in range(0, df.shape[0], chunk_size)\n",
    "    ]\n",
    "    dask.compute(tsk)\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "w = widgets.Dropdown(\n",
    "    options=[(x, k) for k, x in enumerate(filelist[\"name\"])],\n",
    "    value=1,\n",
    "    description=\"Image:\",\n",
    ")\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imaris_ims_file_reader.ims import ims\n",
    "\n",
    "row = filelist.iloc[w.value]\n",
    "resolution_level = 1  # need to be the same than the one used for processing\n",
    "img = ims(get_files(dstdir, row, \"ims\"), ResolutionLevelLock=resolution_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add codes to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(get_files(dstdir, row, \"measurements\"), index_col=0)\n",
    "df = pd.DataFrame(df.to_records())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tifffile.imread(get_files(dstdir, row, \"labels\"))\n",
    "\n",
    "df = pd.read_csv(get_files(dstdir, row, \"measurements\"), index_col=0)\n",
    "df = pd.DataFrame(df.to_records())\n",
    "\n",
    "channels = get_measurement_channels(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the intensity on the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_intensity = map_intensity(labels, df, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the map of intensity to select threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default thresholds\n",
    "thresholds = {c: df[c].median() + 0.5 * madstd(df[c]) for c in channels}\n",
    "# custom threshold\n",
    "thresholds = {\"tbh\": 0.5, \"LGC007\": 0.1, \"vacht\": 0.1}\n",
    "fig, ax = plt.subplots(1, len(channels))\n",
    "for k, ch in enumerate(channels):\n",
    "    ax[k].imshow(\n",
    "        cell_intensity[k, cell_intensity.shape[1] // 2] > thresholds[ch], cmap=\"gray\"\n",
    "    )\n",
    "    ax[k].set_axis_off()\n",
    "    ax[k].set_title(f\"{ch}>{thresholds[ch]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the combination of channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_in, decoder_in = encode_channels_inclusive(df, channels, thresholds)\n",
    "codes_ex, decoder_ex = encode_channels_exclusive(df, channels, thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the cells as points for a quick visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "scatter = ax.scatter(df[\"x\"], df[\"y\"], c=codes_ex[\"id\"], cmap=\"Set1\", alpha=0.25)\n",
    "ax.axis(\"equal\")\n",
    "ax.set_title(\"Exclusive categories\")\n",
    "ax.invert_yaxis()\n",
    "plt.axis(\"off\")\n",
    "fig.legend(\n",
    "    scatter.legend_elements()[0],\n",
    "    [\"+\".join(decoder_ex[k]) for k in range(8)],\n",
    "    loc=\"outside right\",\n",
    "    title=\"Catergories\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the label code map for the exclusive labels (one single label map for encodes all the categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codemaps, features = create_class_image(labels, codes_ex, decoder_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(codemaps.max()-codemaps[codemaps.shape[0]//2],cmap='Set1',interpolation=None)\n",
    "plt.axis('off')\n",
    "plt.title('Exclusive labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the label maps of inclusive labels (one binary map per category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps, names = create_class_masks(labels, codes_in, decoder_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of each inclusive labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(names), figsize=(20, 5))\n",
    "for k in range(len(names)):\n",
    "    ax[k].imshow(np.amax(maps[k, :, ::4, ::4], 0), cmap=\"gray\")\n",
    "    ax[k].set(title=names[k])\n",
    "    ax[k].title.set_fontsize(5)\n",
    "    ax[k].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the result in 3D using napari\n",
    "- toggle the label layer to visualize the codes\n",
    "- on the codemaps layer, tick the 'show selected' option and run through the labels to display the cells code by code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.view_image(\n",
    "    img, channel_axis=1, name=[row[f\"channel{k+1}\"] for k in range(img.shape[1])]\n",
    ")\n",
    "# v.add_labels(labels) # labels is exclusive (categories)\n",
    "# v.add_image(maps,channel_axis=0,name=names) # maps are inclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis and figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inclusive analysis\n",
    "\n",
    "Report the percentable of cell positive for each combination of channel if the cell is positive for any of the channels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with fraction of cells vs  total number of cell in the region\n",
    "tbl_in = (\n",
    "    codes_in.merge(df[[\"label\", \"roi\"]], on=\"label\")\n",
    "    .drop(columns=[\"label\"])\n",
    "    .groupby(\"roi\")  # group per roi\n",
    "    .agg([\"count\", \"sum\"])  # count cell and positive cells\n",
    "    .groupby(axis=1, level=0)  # group per category\n",
    "    .apply(lambda df: 100 * df[df.columns[1]] / df[df.columns[0]])\n",
    ")  # ratio\n",
    "tbl_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(tbl_in.T)\n",
    "plt.title(\"Percentage of cell per ROI per category (inclusive)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclusive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_ex = (\n",
    "    codes_ex.merge(df[[\"label\", \"roi\"]], on=\"label\")\n",
    "    .groupby([\"roi\", \"id\"])\n",
    "    .agg(\"count\")\n",
    "    .reset_index()\n",
    ")\n",
    "tbl_ex[\"category\"] = [\"+\".join(decoder_ex[x]) for x in tbl_ex[\"id\"]]\n",
    "tbl_ex = tbl_ex.pivot_table(values=\"label\", columns=\"category\", index=\"roi\")\n",
    "tbl_ex = tbl_ex.apply(lambda x: 100 * x / x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(tbl_ex.T)\n",
    "plt.title(\"Percentage of cell per ROI per category (exclusive)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
