{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and statistical analysis\n",
    "\n",
    "Save the results as a 'destination folder/*-stats.csv' file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the result folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "srcdir, dstdir = '', ''\n",
    "if Path(\"config.yml\").exists():\n",
    "    with open(\"config.yml\", \"r\") as file:    \n",
    "        config = yaml.safe_load(file)\n",
    "        if 'source' in config.keys():\n",
    "            srcdir = Path(config[\"source\"])        \n",
    "        if 'destination' in config.keys():\n",
    "            dstdir = Path(config[\"destination\"]) \n",
    "\n",
    "fc = FileChooser(dstdir, select_desc='Destination')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dstdir = Path(fc.selected) if fc.selected is not None else Path(dstdir)\n",
    "filelistname = dstdir / 'filelist.csv'\n",
    "filelist = pd.read_csv(filelistname)\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "from functools import partial\n",
    "from functools import reduce  \n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import napari\n",
    "\n",
    "def get_files(dstdir, row, key=None):\n",
    "    if key == 'ims':\n",
    "        return Path(row['folder']) / row['name']\n",
    "    elif key == 'regions':\n",
    "        return Path(dstdir / str(row[\"name\"]).replace('.ims','-regions.json'))\n",
    "    elif key == 'labels':\n",
    "        return Path(dstdir / str(row['name']).replace('.ims','-labels.tif'))\n",
    "    elif key == 'measurements':\n",
    "        return Path(dstdir / str(row['name']).replace('.ims','-measurements.csv'))\n",
    "    elif key == 'stats':\n",
    "        return Path(dstdir / str(row['name']).replace('.ims','-stats.csv'))\n",
    "    else:\n",
    "        return {\n",
    "            'ims': get_files(dstdir, row, 'ims'),\n",
    "            'regions': get_files(dstdir, row, 'regions'),\n",
    "            'labels': get_files(dstdir, row, 'labels'),\n",
    "            'measurements':  get_files(dstdir, row, 'measurements')\n",
    "        }\n",
    "    \n",
    "def get_measurement_channels(df):\n",
    "    \"\"\"List the channels name from the measurement data\"\"\"\n",
    "    return df.columns[6:]    \n",
    "    \n",
    "def create_heatmaps(labels, df):    \n",
    "    channel_columns = [f'c{k}' for k in range(10) if f'c{k}' in df.columns]\n",
    "\n",
    "    heatmaps = np.zeros([len(channel_columns), *labels.shape])\n",
    "    for row in df.iloc:\n",
    "        for k, c in enumerate(channel_columns):\n",
    "                heatmaps[k][labels == row['label']] = row[c]  \n",
    "    return heatmaps\n",
    "\n",
    "def madstd(x):\n",
    "    \"\"\"Median std\"\"\"\n",
    "    return 1.48 * np.median(np.abs(x-np.median(x)))\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"Compute the powerset of iterable\"\"\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def encode(row, channels, thresholds, encoder):\n",
    "    \"\"\"compute a code from the channels columns and the tresholds\"\"\"\n",
    "    t = tuple([c for c in channels if row[c] > thresholds[c]])\n",
    "    return encoder[t]\n",
    "\n",
    "def encode_channels_exclusive(df, columns, thresholds):\n",
    "    \"\"\"Encode the channel in the data frame based on intensity \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    columns : List[str]\n",
    "        list of columns names\n",
    "    thresholds: List[float]\n",
    "        list of threshold values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    code_df and encoder, decoder dicts\n",
    "    \"\"\"\n",
    "    pset = [x for x in powerset(columns)]\n",
    "    encoder = {x:k for k,x in enumerate(pset)}\n",
    "    decoder = {k:x for k,x in enumerate(pset)}\n",
    "    decoder[0] = ('none',)\n",
    "    decode_str = {a:b for a,b in enumerate(['+'.join([str(e) for e in k]) for k in encoder.keys()])}\n",
    "    cid = df.apply(partial(encode, channels=columns, encoder=encoder, thresholds=thresholds), axis=1)\n",
    "    code_df = pd.DataFrame({     \n",
    "        'label': df['label'],\n",
    "        'id': cid})\n",
    "    return code_df, decoder\n",
    "\n",
    "def prod(iterable):\n",
    "    return reduce(operator.mul, iterable, 1)\n",
    "\n",
    "def encode_channels_inclusive(df, columns, thresholds):\n",
    "    \"\"\"Encode the channel in the data frame based on intensity \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    channels : List[str]\n",
    "        list of channel names\n",
    "    thresholds: List[float]\n",
    "        list of threshold values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    code_df and encoder, decoder dicts\n",
    "    \"\"\"\n",
    "    pset = [x for x in powerset(columns)]       \n",
    "    decoder = {k+1:'+'.join([str(e) for e in x]) for k,x in enumerate(pset[1:])}    \n",
    "    code_df = pd.DataFrame({\n",
    "        '+'.join([str(e) for e in k]) : prod([df[e] > thresholds[e] for e in k]) for k in pset[1:]\n",
    "        })\n",
    "    code_df['label'] = df['label']\n",
    "    return code_df, decoder\n",
    "\n",
    "def create_class_image(labels, codes, decoder):\n",
    "    \"\"\"Create a map of the binary codes as a label map\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    labels: np.array\n",
    "\n",
    "    codes: pd.DataFrame\n",
    "        data frame with a column label and a label code\n",
    "\n",
    "    decoder: dict\n",
    "        dictionary: {id: tuple(combination columns names)}\n",
    "\n",
    "    Note add 1 to the code so that it is not set to background\n",
    "    \"\"\"\n",
    "    stack = np.zeros(labels.shape, dtype=np.uint8)\n",
    "    for row in codes.iloc:\n",
    "        stack[labels == row['label']] = row['id'] + 1        \n",
    "    features = pd.DataFrame({'code':[ 'background', *[' + '.join(decoder[k]) for k in decoder ]]})\n",
    "    return stack, features\n",
    "\n",
    "def create_class_masks(labels, codes, decoder):\n",
    "    \"\"\"Create a set of maps for each combination of labels\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    labels: np.array\n",
    "\n",
    "    codes: pd.DataFrame\n",
    "        data frame with a column label and a column per combination\n",
    "\n",
    "    decoder: dict\n",
    "        dictionary: {id: tuple(combination columns names)}    \n",
    "\n",
    "    \"\"\"\n",
    "    nc = len(decoder)\n",
    "    stack = np.zeros([nc, *labels.shape], dtype=np.uint8)\n",
    "    for row in codes.iloc:        \n",
    "        for c in decoder:\n",
    "            if row[decoder[c]] == 1:\n",
    "                stack[c-1][labels == row['label']] = 255    \n",
    "    names = [decoder[k] for k in decoder ]    \n",
    "    return stack, names\n",
    "    \n",
    "def aggregate_combinations(input, decoder):\n",
    "    \"\"\"Aggregate the inputs based on combinations in the decoder\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input: pd.DataFrame or np.array\n",
    "        input on which to compute the aggregation\n",
    "    decoder: dict\n",
    "        mapping between keys of the input and the corresponding set of channels\n",
    "    \"\"\"\n",
    "    output = input.copy()\n",
    "    for k1 in decoder:        \n",
    "        for k2 in decoder:            \n",
    "            if len(decoder[k2]) > len(decoder[k1]):\n",
    "                for y1 in decoder[k1]:\n",
    "                    if y1 in decoder[k2]:\n",
    "                        output[k1] = output[k1] + input[k2]\n",
    "    return output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "w = widgets.Dropdown(\n",
    "    options=[(x,k) for k,x in enumerate(filelist['name'])],\n",
    "    value=1,\n",
    "    description='Image:'\n",
    ")\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imaris_ims_file_reader.ims import ims\n",
    "row = filelist.iloc[w.value]\n",
    "resolution_level = 1 # need to be the same than the one used for processing\n",
    "img = ims(get_files(dstdir, row, 'ims'), ResolutionLevelLock=resolution_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add codes to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(get_files(dstdir, row, 'measurements'), index_col=0)\n",
    "df = pd.DataFrame(df.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tifffile.imread(get_files(dstdir, row, 'labels'))\n",
    "\n",
    "df = pd.read_csv(get_files(dstdir, row, 'measurements'), index_col=0)\n",
    "df = pd.DataFrame(df.to_records())\n",
    "\n",
    "channels = get_measurement_channels(df)\n",
    "\n",
    "# compute the thresholds\n",
    "thresholds = {c:df[c].median() + 0.5 * madstd(df[c]) for c in channels}            \n",
    "\n",
    "for k,c in enumerate(channels):\n",
    "    df[f'z{k}'] = (df[c] - df[c].median()) / madstd(df[c])\n",
    "\n",
    "codes_in, decoder_in = encode_channels_inclusive(df, channels, thresholds)\n",
    "codes_ex, decoder_ex = encode_channels_exclusive(df, channels, thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the label code map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codemaps, features = create_class_image(labels, codes_ex, decoder_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps, names = create_class_masks(labels, codes_in, decoder_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,len(names),figsize=(20,5))\n",
    "for k in range(len(names)):         \n",
    "    ax[k].imshow(np.amax(maps[k,:,::4,::4],0), cmap='gray')\n",
    "    ax[k].set(title=names[k])\n",
    "    ax[k].title.set_fontsize(5)\n",
    "    ax[k].set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the result\n",
    "- toggle the label layer to visualize the codes\n",
    "- on the codemaps layer, tick the 'show selected' option and run through the labels to display the cells code by code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.view_image(img, channel_axis=1, name=[row[f'channel{k+1}'] for k in range(img.shape[1])])\n",
    "v.add_labels(labels)\n",
    "v.add_image(maps,channel_axis=0,name=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis and figure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the proportion of cell class in each region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = codes_in.merge(df[['label','roi']],on='label').drop(columns=['label']).groupby('roi').agg('sum')\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(tbl.T)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
