{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and statistical analysis\n",
    "\n",
    "Save the results as a 'destination folder/*-stats.csv' file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the result folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "srcdir, dstdir = '', ''\n",
    "if Path(\"config.yml\").exists():\n",
    "    with open(\"config.yml\", \"r\") as file:    \n",
    "        config = yaml.safe_load(file)\n",
    "        if 'source' in config.keys():\n",
    "            srcdir = Path(config[\"source\"])        \n",
    "        if 'destination' in config.keys():\n",
    "            dstdir = Path(config[\"destination\"]) \n",
    "\n",
    "fc = FileChooser(dstdir, select_desc='Destination')\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dstdir = Path(fc.selected) if fc.selected is not None else Path(dstdir)\n",
    "filelistname = dstdir / 'filelist.csv'\n",
    "filelist = pd.read_csv(filelistname)\n",
    "filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "import napari\n",
    "\n",
    "def get_files(dstdir, row, key=None):\n",
    "    if key == 'ims':\n",
    "        return Path(row['folder']) / row['name']\n",
    "    elif key == 'regions':\n",
    "        return Path(dstdir / str(row[\"name\"]).replace('.ims','-regions.json'))\n",
    "    elif key == 'labels':\n",
    "        return Path(dstdir / str(row['name']).replace('.ims','-labels.tif'))\n",
    "    elif key == 'measurements':\n",
    "        return Path(dstdir / str(row['name']).replace('.ims','-measurements.csv'))\n",
    "    elif key == 'stats':\n",
    "        return Path(dstdir / str(row['name']).replace('.ims','-stats.csv'))\n",
    "    else:\n",
    "        return {\n",
    "            'ims': get_files(dstdir, row, 'ims'),\n",
    "            'regions': get_files(dstdir, row, 'regions'),\n",
    "            'labels': get_files(dstdir, row, 'labels'),\n",
    "            'measurements':  get_files(dstdir, row, 'measurements')\n",
    "        }\n",
    "    \n",
    "def get_measurement_channels(df):\n",
    "    \"\"\"List the channels name from the measurement data\"\"\"\n",
    "    return df.columns[6:]    \n",
    "    \n",
    "def create_heatmaps(labels, df):    \n",
    "    channel_columns = [f'c{k}' for k in range(10) if f'c{k}' in df.columns]\n",
    "\n",
    "    heatmaps = np.zeros([len(channel_columns), *labels.shape])\n",
    "    for row in df.iloc:\n",
    "        for k, c in enumerate(channel_columns):\n",
    "                heatmaps[k][labels == row['label']] = row[c]  \n",
    "    return heatmaps\n",
    "\n",
    "def madstd(x):\n",
    "    \"\"\"Median std\"\"\"\n",
    "    return 1.48 * np.median(np.abs(x-np.median(x)))\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"\"\"Compute the powerset of iterable\"\"\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def encode(row, channels, thresholds, encoder):\n",
    "    \"\"\"compute a code from the channels columns and the tresholds\"\"\"\n",
    "    t = tuple([c for c in channels if row[c] > thresholds[c]])\n",
    "    return encoder[t]\n",
    "\n",
    "def encode_channels(df, channels, thresholds):\n",
    "    \"\"\"Encode the channel in the data frame based on intensity (in place)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    channels : List[str]\n",
    "        list of channel names\n",
    "    thresholds: List[float]\n",
    "        list of threshold values\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    encoder decoder dicts\n",
    "    \"\"\"\n",
    "    pset = [x for x in powerset(channels)]\n",
    "    encoder = {x:k for k,x in enumerate(pset)}\n",
    "    decoder = {k:x for k,x in enumerate(pset)}\n",
    "    decoder[0] = ('none',)\n",
    "    df['code id'] = df.apply(partial(encode, channels=channels, encoder=encoder, thresholds=thresholds), axis=1)\n",
    "    decode_str = {a:b for a,b in enumerate(['+'.join([str(e) for e in k]) for k in encoder.keys()])}\n",
    "    df['code str'] = [decode_str[k] for k in df['code id']]\n",
    "    return encoder, decoder\n",
    "\n",
    "def create_codemap(labels, df, decoder):\n",
    "    \"\"\"Create a map of the binary codes as a label map\n",
    "    \n",
    "    Note add 1 to the code so that it is not set to background\n",
    "    \"\"\"\n",
    "    stack = np.zeros(labels.shape, dtype=np.uint8)\n",
    "    for row in df.iloc:\n",
    "        stack[labels == row['label']] = row['code id'] + 1        \n",
    "    features = pd.DataFrame({'code':[ 'background', *[' + '.join(decoder[k]) for k in decoder ]]})\n",
    "    return stack, features\n",
    "\n",
    "def create_maps(labels, df, decoder):\n",
    "    \"\"\"Create a set of maps for each combination of labels\"\"\"\n",
    "    nc = len(decoder)\n",
    "    stack = np.zeros([nc, *labels.shape], dtype=np.uint8)\n",
    "    for row in df.iloc:\n",
    "        c = row['code id']        \n",
    "        stack[c][labels == row['label']] = 255    \n",
    "    names = [' + '.join(decoder[k]) for k in decoder ]\n",
    "    return stack, names\n",
    "    \n",
    "def aggregate_combinations(input, decoder):\n",
    "    \"\"\"Aggregate the inputs based on combinations in the decoder\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input: pd.DataFrame or np.array\n",
    "        input on which to compute the aggregation\n",
    "    decoder: dict\n",
    "        mapping between keys of the input and the corresponding set of channels\n",
    "    \"\"\"\n",
    "    output = input.copy()\n",
    "    for k1 in decoder:        \n",
    "        for k2 in decoder:            \n",
    "            if len(decoder[k2]) > len(decoder[k1]):\n",
    "                for y1 in decoder[k1]:\n",
    "                    if y1 in decoder[k2]:\n",
    "                        output[k1] = output[k1] + input[k2]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "w = widgets.Dropdown(\n",
    "    options=[(x,k) for k,x in enumerate(filelist['name'])],\n",
    "    value=1,\n",
    "    description='Image:'\n",
    ")\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imaris_ims_file_reader.ims import ims\n",
    "row = filelist.iloc[w.value]\n",
    "resolution_level = 1 # need to be the same than the one used for processing\n",
    "img = ims(get_files(dstdir, row, 'ims'), ResolutionLevelLock=resolution_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add codes to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(get_files(dstdir, row, 'measurements'), index_col=0)\n",
    "df = pd.DataFrame(df.to_records())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tifffile.imread(get_files(dstdir, row, 'labels'))\n",
    "\n",
    "df = pd.read_csv(get_files(dstdir, row, 'measurements'), index_col=0)\n",
    "df = pd.DataFrame(df.to_records())\n",
    "\n",
    "channels = get_measurement_channels(df)\n",
    "\n",
    "# compute the thresholds\n",
    "thresholds = {c:df[c].median() + 0.5 * madstd(df[c]) for c in channels}            \n",
    "\n",
    "for k,c in enumerate(channels):\n",
    "    df[f'z{k}'] = (df[c] - df[c].median()) / madstd(df[c])\n",
    "\n",
    "encoder, decoder = encode_channels(df, channels, thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the label code map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codemaps, features = create_codemap(labels, df, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps, names = create_maps(labels, df, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,len(names),figsize=(20,5))\n",
    "for k in range(len(names)):         \n",
    "    ax[k].imshow(np.amax(maps[k,:,::4,::4],0), cmap='gray')\n",
    "    ax[k].set(title=names[k])\n",
    "    ax[k].title.set_fontsize(5)\n",
    "    ax[k].set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute aggregated maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapsagg = aggregate_combinations(maps, {k: tuple(c.split(' + ')) for k,c  in enumerate(names)} )\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,len(names),figsize=(20,5))\n",
    "for k in range(len(names)):         \n",
    "    ax[k].imshow(np.amax(mapsagg[k,:,::4,::4],0), cmap='gray')\n",
    "    ax[k].set(title=names[k])\n",
    "    ax[k].title.set_fontsize(5)\n",
    "    ax[k].set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the result\n",
    "- toggle the label layer to visualize the codes\n",
    "- on the codemaps layer, tick the 'show selected' option and run through the labels to display the cells code by code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = napari.view_image(img, channel_axis=1, name=[row[f'channel{k+1}'] for k in range(img.shape[1])])\n",
    "v.add_labels(labels)\n",
    "v.add_image(mapsagg,channel_axis=0,name=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analysis and figure\n",
    "## Without aggregation by set labels\n",
    "We first count the number of cell in each class and create a pivot table to visualize the results. Here the results are by class before aggregation of the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = pd.pivot_table(df.groupby(['roi','code str'])['label'].agg('count').to_frame(), values='label', index='roi',columns='code str').fillna(0)\n",
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.T.plot(kind='barh')\n",
    "plt.title(f\"Count of cell class in each region {row['name']}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the proportion of cell class in each region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative = 100*tbl.div(tbl.sum(axis=1), axis=0)\n",
    "relative.to_csv(get_files(dstdir, row, 'stats'))\n",
    "relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative.T.plot(kind='barh')\n",
    "plt.title(f\"Proportion of cell class in each region {row['name']}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating cells in sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblagg = aggregate_combinations(tbl,{c: tuple(c.split('+')) for c  in tbl.columns} )\n",
    "tblagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblagg.T.plot(kind='barh')\n",
    "plt.title(f\"Count of cell label in each region {row['name']}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again compute the proportion of cells in each set. Here the total is still the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relativeagg = 100*tblagg.div(tbl.sum(axis=1), axis=0)\n",
    "relative.to_csv(get_files(dstdir, row, 'stats'))\n",
    "relativeagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relativeagg.T.plot(kind='barh')\n",
    "plt.title(f\"Proportion of cell class in each region {row['name']}\");"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
